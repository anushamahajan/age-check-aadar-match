import os
import nest_asyncio
import uuid
import shutil
from typing import List, Dict, Any, Union

# install with: pip install llama-parse Pillow img2pdf
from llama_parse import LlamaParse
from PIL import Image 
import img2pdf

# LlamaIndex schema for nodes (useful for downstream LLM processing)
from llama_index.core.schema import ImageDocument, TextNode

nest_asyncio.apply()

class DocumentProcessorService:
    """
    A service class to encapsulate document processing functionalities,
    including image-to-PDF conversion and LlamaParse integration.
    """

    def __init__(self, llama_cloud_api_key: str, temp_storage_dir: str = "./backend_temp_data"):
        """
        Initializes the DocumentProcessorService.

        Args:
            llama_cloud_api_key (str): Your API key for Llama Cloud.
            temp_storage_dir (str): Directory to store temporary files (e.g., uploaded files,
                                    converted PDFs, extracted images).
        """
        if not llama_cloud_api_key:
            raise ValueError("LLAMA_CLOUD_API_KEY environment variable is not set. Please provide it.")
        self.llama_cloud_api_key = llama_cloud_api_key
        self.temp_storage_dir = temp_storage_dir
        os.makedirs(self.temp_storage_dir, exist_ok=True)
        # Initialize LlamaParse client once
        self.parser = LlamaParse(
            api_key=self.llama_cloud_api_key,
            result_type="json", # Requesting raw JSON output from LlamaParse
        )
        print(f"DocumentProcessorService initialized. Temp files will be stored in: {self.temp_storage_dir}")


    def _generate_unique_filepath(self, original_filename: str, prefix: str = "", extension: str = "") -> str:
        """
        Generates a unique file path within the temporary storage directory.

        Args:
            original_filename (str): The original name of the file.
            prefix (str): A prefix to add to the unique filename.
            extension (str): The desired file extension (e.g., ".pdf", ".png").

        Returns:
            str: A unique file path.
        """
        filename_base = os.path.splitext(os.path.basename(original_filename))[0]
        unique_id = uuid.uuid4().hex
        if not extension: # Use original extension if not specified
            extension = os.path.splitext(original_filename)[1]
        return os.path.join(self.temp_storage_dir, f"{prefix}{filename_base}_{unique_id}{extension}")


    def convert_image_to_pdf(self, image_input_path: str) -> Union[str, None]:
        """
        Converts an image file (PNG, JPEG, etc.) to a PDF file.

        Args:
            image_input_path (str): The file path to the input image.

        Returns:
            Union[str, None]: The file path to the generated PDF, or None if conversion fails.
        """
        if not os.path.exists(image_input_path):
            print(f"Error: Image file not found at {image_input_path}")
            return None

        # Generate a unique path for the output PDF
        output_pdf_path = self._generate_unique_filepath(image_input_path, prefix="converted_img_", extension=".pdf")

        try:
            with open(output_pdf_path, "wb") as f:
                # img2pdf is efficient and often lossless for supported image formats
                f.write(img2pdf.convert(image_input_path))
            print(f"Successfully converted '{image_input_path}' to '{output_pdf_path}'")
            return output_pdf_path
        except Exception as e:
            print(f"Error converting image '{image_input_path}' to PDF: {e}")
            return None


    def process_pdf_for_extraction(self, pdf_file_path: str) -> Dict[str, Any]:
        """
        Processes a PDF file using LlamaParse to extract text and image information.

        Args:
            pdf_file_path (str): The file path to the input PDF document.

        Returns:
            Dict[str, Any]: A dictionary containing:
                - 'raw_llamaparse_json': The full JSON output generated by LlamaParse.
                - 'text_nodes': A list of LlamaIndex TextNode objects.
                - 'image_documents': A list of LlamaIndex ImageDocument objects.
                - 'error': Error message if processing fails, otherwise None.
        """
        if not os.path.exists(pdf_file_path):
            return {
                "raw_llamaparse_json": {},
                "text_nodes": [],
                "image_documents": [],
                "error": f"PDF file not found at {pdf_file_path}"
            }

        print(f"Processing PDF for extraction: {pdf_file_path}")
        try:
            # Step 1: Get the raw JSON result from LlamaParse
            # LlamaParse's get_json_result sends the file to the Llama Cloud API
            # and returns a list of results (one per job/file in this case).
            # This 'raw_llamaparse_responses' is what 'parser.get_images' expects.
            raw_llamaparse_responses = self.parser.get_json_result(pdf_file_path)

            if not raw_llamaparse_responses:
                return {
                    "raw_llamaparse_json": {},
                    "text_nodes": [],
                    "image_documents": [],
                    "error": "LlamaParse returned an empty result or failed to parse."
                }

            # For a single file processing request, we typically take the first (and often only) response
            full_llamaparse_json = raw_llamaparse_responses[0] # This is the detailed JSON for the document

            # Step 2: Extract text nodes from the LlamaParse JSON
            text_nodes: List[TextNode] = []
            if "pages" in full_llamaparse_json:
                for page_data in full_llamaparse_json["pages"]:
                    if "text" in page_data and page_data["text"]:
                        text_nodes.append(
                            TextNode(
                                text=page_data["text"],
                                metadata={
                                    "page_number": page_data.get("page", "N/A"),
                                    "source_file": os.path.basename(pdf_file_path)
                                }
                            )
                        )
            print(f"Extracted {len(text_nodes)} text nodes from {pdf_file_path}.")

            # Step 3: Extract image documents (downloads images to temp_storage_dir)
            image_documents: List[ImageDocument] = []
            try:
                # parser.get_images takes the original raw_llamaparse_responses (list of job results)
                # and downloads images referenced in them to the specified download_path.
                downloaded_image_dicts = self.parser.get_images(raw_llamaparse_responses, download_path=self.temp_storage_dir)
                for img_dict in downloaded_image_dicts:
                    # img_dict contains 'path' to the locally downloaded image file
                    image_documents.append(
                        ImageDocument(
                            image_path=img_dict["path"],
                            metadata={
                                "page_number": img_dict.get("page", "N/A"),
                                "source_file": os.path.basename(pdf_file_path)
                            }
                        )
                    )
                print(f"Extracted {len(image_documents)} image documents from {pdf_file_path}.")
            except Exception as img_e:
                print(f"Warning: Could not extract/download images using LlamaParse's get_images for {pdf_file_path}: {img_e}")
                # Continue without images if there's an error in this specific step

            return {
                "raw_llamaparse_json": full_llamaparse_json, # The detailed JSON for the document
                "text_nodes": text_nodes,
                "image_documents": image_documents,
                "error": None
            }

        except Exception as e:
            print(f"Error processing PDF '{pdf_file_path}' with LlamaParse: {e}")
            return {
                "raw_llamaparse_json": {},
                "text_nodes": [],
                "image_documents": [],
                "error": str(e)
            }

    def cleanup_temp_files(self, file_paths: Union[str, List[str]]):
        """
        Cleans up temporary files from the temp_storage_dir.
        Ensures files are within the designated temporary directory for safety.

        Args:
            file_paths (Union[str, List[str]]): A single file path or a list of file paths to delete.
        """
        if isinstance(file_paths, str):
            file_paths = [file_paths]

        # Get the absolute path of the temporary directory for safe comparison
        abs_temp_dir = os.path.abspath(self.temp_storage_dir)

        for path in file_paths:
            try:
                abs_path = os.path.abspath(path)
                # Only delete if the file exists AND is within our temp storage directory
                if os.path.exists(abs_path) and abs_path.startswith(abs_temp_dir):
                    if os.path.isfile(abs_path):
                        os.remove(abs_path)
                        print(f"Cleaned up temporary file: {abs_path}")
                    elif os.path.isdir(abs_path):
                        shutil.rmtree(abs_path) # Remove directory and its contents
                        print(f"Cleaned up temporary directory: {abs_path}")
                else:
                    print(f"Skipping cleanup for non-temp, non-existent, or invalid path: {abs_path}")
            except Exception as e:
                print(f"Error cleaning up file/directory {abs_path}: {e}")